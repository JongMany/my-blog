---
title: SSE 기반 LLM 스트리밍 UX
summary: 패턴 분석기·스케줄러로 배치 크기/렌더 간격 동적 조절, RAF 버퍼링, 자동 스크롤 등 지터 최소화.
project: BubbleChat
order: 1.2
tags: [기능 개선]
date: 2024-12-15
cover: /projects/thumbnails/gifs/llm-streaming.gif
coverAlt: "LLM 스트리밍 데모"
coverCaption: "실시간으로 토큰이 스트리밍되는 LLM 응답"
coverType: gif
coverAspectRatio: 16:9
---

## 개요

LLM 응답이 완료되기 전까지 아무것도 보이지 않는 빈 화면이 노출되어 사용자가 AI가 작동하는지 확신하기 어려웠던 상황을 해결하기 위해 SSE 기반 실시간 스트리밍 시스템을 구현했습니다.

## 배경/문제

- LLM 응답이 완료되기 전까지 아무것도 보이지 않는 빈 화면이 노출되어 사용자가 AI가 작동하는지 확신하기 어려웠던 상황

## 해결 방안

### SSE 스트리밍 구현

- 토큰 단위 실시간 스트리밍으로 즉각적 피드백
- 연결 상태 관리 (idle → connecting → streaming → done)
- 자동 재연결 및 에러 복구 메커니즘

### LLM UI 라이브러리 통합

llm-ui 라이브러리를 통해 마크다운 및 코드 블록 실시간 렌더링을 구현했습니다.

### 성능 최적화

- **StreamPatternAnalyzer/StreamScheduler 설계**: 배치 크기/렌더 간격 동적 조절
- **RAF 버퍼링**: 렌더링 프레임 최적화
- **자동 스크롤**: 지터 최소화
- **MSW 모킹**: 지연/에러 시나리오 테스트 생산성 향상

## 결과

- LLM 응답에 대한 체감 대기 시간 단축
- 실시간 피드백으로 사용자 경험 개선
- 개발 환경에서 테스트 효율성 향상
